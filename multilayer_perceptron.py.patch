--- multilayer_perceptron.py    2019-02-18 17:25:10.000000000 +0000
+++ example-nn.py       2019-02-18 17:33:24.000000000 +0000
@@ -22,7 +22,7 @@
 
 # Import MNIST data
 from tensorflow.examples.tutorials.mnist import input_data
-mnist = input_data.read_data_sets("/tmp/data/", one_hot=True)
+mnist = input_data.read_data_sets("/home/a.cos/neuralnet_data/", one_hot=True)
 
 import tensorflow as tf
 
@@ -65,16 +65,19 @@
     out_layer = tf.matmul(layer_2, weights['out']) + biases['out']
     return out_layer
 
-# Construct model
-logits = multilayer_perceptron(X)
 
-# Define loss and optimizer
-loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(
-    logits=logits, labels=Y))
-optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)
-train_op = optimizer.minimize(loss_op)
-# Initializing the variables
-init = tf.global_variables_initializer()
+#setup GPU
+with tf.device('/gpu:0'):
+
+    # Construct model
+    logits = multilayer_perceptron(X)
+
+    # Define loss and optimizer
+    loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y))
+    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)
+    train_op = optimizer.minimize(loss_op)
+    # Initializing the variables
+    init = tf.global_variables_initializer()
 
 with tf.Session() as sess:
     sess.run(init)
